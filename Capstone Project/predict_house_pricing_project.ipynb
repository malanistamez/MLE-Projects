{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"c0111f8d98b300cddecdb814fd4fa6548c49a866"},"source":["### **Capstone Project Proposal: Predicting Housing Prices with Machine Learning**\n","\n","\n","## Background\n","I'm excited to delve into the realm of machine learning with my first project using AWS SageMaker. My aim is to explore data analysis and model training on the SageMaker platform by tackling the challenge of predicting housing prices.\n","\n","## Contents\n","\n","1. [Background](#Background)\n","2. [Approach](#Approach)\n","3. [Environment](#Environment)\n","4. [Data](#Data)\n","5. [SageMaker](#SageMaker)\n","6. [Hyperparameters](#Hyperparameters)\n","7. [Conclusions](#Conclusions)\n","\n","## Approach\n","\n","For this project, I'm not aiming for a top-ranking solution in the \"House Prices\" Kaggle competition. Instead, I'm focusing on leveraging SageMaker's infrastructure to develop a model that outperforms a naive solution. Given the wealth of information available on the Kaggle competition page, I'll skip extensive data exploration and feature engineering.\n","\n","My plan is to use a default algorithm provided by SageMaker, with eXtreme Gradient Boosting (XGBoost) being a promising choice for regression problems like this. To kickstart the process, I'll utilize a SageMaker example notebook on XGBoost, allowing me to bypass syntax hunting and focus on the workflow.\n","\n","## Environment\n","\n","### AWS Setup\n","1. Begin by setting up an AWS account on aws.amazon.com.\n","2. Access the SageMaker service and create a new notebook instance.\n","3. Opt for a cost-effective instance type like \"ml.t2.medium\" to keep expenses minimal.\n","4. Utilize the default IAM role for simplicity.\n","5. Start the notebook instance and open a terminal for future use.\n","\n","## Data\n","\n","I'll be using the dataset provided by the \"House Prices\" Kaggle competition. This dataset contains various features such as square footage, number of bedrooms, and location details, which will be used to predict housing prices.\n","\n","## SageMaker\n","\n","I'll employ AWS SageMaker for data preprocessing, model training, and evaluation. This cloud-based platform offers a streamlined workflow for building and deploying machine learning models at scale.\n","\n","## Hyperparameters\n","\n","Given the simplicity of this project, I'll primarily rely on default hyperparameters provided by the chosen algorithm. However, I'll explore tuning them if time permits to enhance model performance.\n","\n","## Conclusions\n","\n","In this project, I aim to gain hands-on experience with AWS SageMaker and machine learning workflows. While the focus is not on achieving top-tier performance in the Kaggle competition, I expect to develop a functional model that demonstrates proficiency in utilizing SageMaker's capabilities. Moving forward, I plan to explore more advanced techniques and delve deeper into feature engineering for improved predictions."]},{"cell_type":"markdown","metadata":{"_uuid":"0564a9e562ab7d98ac645ea90834f84505b013bd"},"source":["### Enabling Kaggle Tools\n","For convenience, let's enable the Kaggle API and command line tools. First, we install the Python package to get the command line tools."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"291102e642dcbb2393aff02d384941b100070e3d"},"outputs":[],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"18de81aaa7b56eaefcdeaa641a6c4e11440c5c49"},"outputs":[],"source":["!kaggle competitions list"]},{"cell_type":"markdown","metadata":{"_uuid":"488115f1b00314f26fa58bcf713ed6dcac314ac7"},"source":["__Kaggle API__\n","\n","Then we enable the Kaggle API. This assumes you have an account on Kaggle. It's free and only takes a minute. Once you have that, follow instructions here to retrieve your kaggle.json file\n","\n","https://github.com/Kaggle/kaggle-api\n","\n","Using the AWS Jupyter files tab, upload your kaggle.json. I had to use the Jupyter terminal to move it to ~/.kaggle/"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"be36c83b328401dfa411aafa8fee764915fccbb2"},"outputs":[],"source":["!mkdir ~/.kaggle\n","!mv kaggle.json ../.kaggle/"]},{"cell_type":"markdown","metadata":{"_uuid":"756cc68d55bf43d5afbeca8fe37b72160ef27a8c"},"source":["Finally, we follow the advice to make sure our Kaggle key isn't readable by other users of this system. This is a corner we could have cut on this private EC2 instance."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"50398291fdeb3620b22f68e3d71639a166e01bad"},"outputs":[],"source":["!chmod 600 ../.kaggle/kaggle.json"]},{"cell_type":"markdown","metadata":{"_uuid":"ec662db184758865108721b6281a7cb5f38bba0a"},"source":["### Python and SageMaker Setup\n","\n","Now we start coding in Python. We import the necessary libraries and create a connection to the SageMaker service."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"221ad79507c1349cf16d43a85793c92404c4b798"},"outputs":[],"source":["import numpy as np                                # For matrix operations and numerical processing\n","import pandas as pd                               # For munging tabular data\n","import matplotlib.pyplot as plt                   # For charts and visualizations\n","from IPython.display import Image                 # For displaying images in the notebook\n","from IPython.display import display               # For displaying outputs in the notebook\n","from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n","import sys                                        # For writing outputs to notebook\n","import math                                       # For ceiling function\n","import json                                       # For parsing hosting outputs\n","import os                                         # For manipulating filepath names\n","import sagemaker                                  # Amazon SageMaker's Python SDK provides many helper functions\n","from sagemaker.predictor import csv_serializer    # Converts strings for HTTP POST requests on inference"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c66f958e78220c1fce2886c96af6c05da786b0d7","isConfigCell":true},"outputs":[],"source":["bucket = sagemaker.Session().default_bucket()\n","prefix = 'sagemaker/house_price_xgboost'\n"," \n","# Define IAM role\n","import boto3\n","import re\n","from sagemaker import get_execution_role\n","\n","role = get_execution_role()\n","region = boto3.Session().region_name \n","smclient = boto3.Session().client('sagemaker')"]},{"cell_type":"markdown","metadata":{"_uuid":"6a48cfecc4c4c8bbb20343dd5fc3eeb014d71d4f"},"source":["---\n","\n","## Data\n","\n","### Retrieval\n","Let's start by downloading the [direct marketing dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing) from UCI's ML Repository."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"602d2b0a8f42f6958e7c2815b6439fcb48b90758"},"outputs":[],"source":["!kaggle competitions list"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f89922ed73966588639f2f1c9d2ee968a9c4e283"},"outputs":[],"source":["!kaggle competitions download -p ./data house-prices-advanced-regression-techniques"]},{"cell_type":"markdown","metadata":{"_uuid":"569213b66bef5eac9e1d766bc3ad28ad07abceb7"},"source":["### Exploration\n","Now lets read this into a Pandas data frame and take a look, but just a quick one. Normally, we would investigate the data. But because our goal is to get a model trained end-to-end on SageMaker as quickly as possible, we'll skip all those best practices and see what happens."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f260d1ecf69a418e35c6f4170356bf7e3f6f75c1"},"outputs":[],"source":["df_train = pd.read_csv('./data/train.csv')\n","pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n","df_train.head()"]},{"cell_type":"markdown","metadata":{"_uuid":"c4d4be6e42d85d395b9ed22f0cf9d633b127bbff"},"source":["### First submission\n","\n","Before we go further investigating the data and creating sophisticated predictive models, let's make sure we're able to submit something, anything, to the competition. The idea is to validate our pipeline and that we've understood the submission format. And by getting an initial score, we're better able to judge future improvements.\n","\n","The required format is provided in the \"sample_submission.csv\" file retrieved earlier."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f713cb7efc16027d0c295af4c8b17fa3862bff36"},"outputs":[],"source":["!head ./data/sample_submission.csv"]},{"cell_type":"markdown","metadata":{"_uuid":"63c8571298fef75dbb4f1181ed6c2216a854ae01"},"source":["For the purpose of test driving the submission process, we don't need a good result, just a valid one. A trivial attempt would be to use the means of the training set as the answer for all items in the testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9c782d5fc3071b23817cd3f404816e511f62adc7"},"outputs":[],"source":["df_train.describe()['SalePrice']"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9f64867527e63d7ce9e881f5ca2a42f6d3657b2d"},"outputs":[],"source":["df_competition = pd.read_csv('./data/test.csv')\n","df_competition.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"68ede9d9848cc524983bf1e3ee598b3a3938a468"},"outputs":[],"source":["df_submit = pd.DataFrame(df_competition['Id'], dtype=int)\n","df_submit['SalePrice'] = df_train.describe()['SalePrice']['mean']\n","df_submit.head()\n","df_submit.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b59268a703d9d9fa561bfa3df38d77148a73692a"},"outputs":[],"source":["df_submit.to_csv('./data/sub_mean.csv',index=False)\n","!head ./data/sub_mean.csv\n","!tail ./data/sub_mean.csv\n"]},{"cell_type":"markdown","metadata":{"_uuid":"adeab0ba28d11737e56f62ee740833a3767b0c46"},"source":["That is the format we were looking for. Now let's try to submit it through the Kaggle API:\n","\n","> usage: kaggle competitions submit [-h] -f FILE_NAME -m MESSAGE [-q] [competition]"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ca60a4dc5caed4bd67fddb40206e2053e7191143"},"outputs":[],"source":["!kaggle competitions submit -f ./data/sub_mean.csv -m \"Means-based submission\" house-prices-advanced-regression-techniques\n","#\n","# Need UI buffer space so horizontal scrollbar does not get in the way"]},{"cell_type":"markdown","metadata":{"_uuid":"f1f9130b034a76379608ba1fabe1f1311894f6a8"},"source":["On Kaggle.com under \"My submission\", I can see that this trivial technique gives a public score of 0.42949. At the time of this writing, this technique places us 4515 out of 4745 on the public leaderboard. Clearly not a good score, but we didn't expect it to be.\n","\n","Now that our submission pipeline has been validated, we can turn our attention to submitting something more clever through SageMaker."]},{"cell_type":"markdown","metadata":{"_uuid":"853dd0061e1f45425e37b6d612cb48ec3bc2cb09"},"source":["### Data Transformation\n","\n","To create a more sophisticated solution, we should know our data. The pros urge us to do the following:\n","\n","> Cleaning up data is part of nearly every machine learning project.  It arguably presents the biggest risk if done incorrectly and is one of the more subjective aspects in the process.  Several common techniques include:\n","\n",">* Handling missing values: Some machine learning algorithms are capable of handling missing values, but most would rather not.  Options include:\n"," * Removing observations with missing values: This works well if only a very small fraction of observations have incomplete information.\n"," * Removing features with missing values: This works well if there are a small number of features which have a large number of missing values.\n"," * Imputing missing values: Entire [books](https://www.amazon.com/Flexible-Imputation-Missing-Interdisciplinary-Statistics/dp/1439868247) have been written on this topic, but common choices are replacing the missing value with the mode or mean of that column's non-missing values.\n","* Converting categorical to numeric: The most common method is one hot encoding, which for each feature maps every distinct value of that column to its own feature which takes a value of 1 when the categorical feature is equal to that value, and 0 otherwise.\n","* Oddly distributed data: Although for non-linear models like Gradient Boosted Trees, this has very limited implications, parametric models like regression can produce wildly inaccurate estimates when fed highly skewed data.  In some cases, simply taking the natural log of the features is sufficient to produce more normally distributed data.  In others, bucketing values into discrete ranges is helpful.  These buckets can then be treated as categorical variables and included in the model when one hot encoded.\n","* Handling more complicated data types: Mainpulating images, text, or data at varying grains is left for other notebook templates.\n","\n","> Luckily, some of these aspects have already been handled for us, and the algorithm we are showcasing tends to do well at handling sparse or oddly distributed data.  Therefore, let's keep pre-processing simple.\n","\n","So, for the purpose of racing to the end, we'll disregard most of it and simply convert categorical variables to numerical data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"40f242973360a35041c57c8ffeb5e45b7c865335"},"outputs":[],"source":["df_train = pd.get_dummies(df_train)   # Convert categorical variables to sets of indicators\n","df_train.describe()"]},{"cell_type":"markdown","metadata":{"_uuid":"0ab66615d72f348165ae1e4d9cd4293e004c5b88"},"source":["### Feature engineering\n","\n","If we cared about the score, we would totally look into that."]},{"cell_type":"markdown","metadata":{"_uuid":"446a8545ba25750cac699efdc6a98e1c7a8c5e2b"},"source":["We, however, will heed this advice regarding creating a validation test from our test data:\n","\n","> When building a model whose primary goal is to predict a target value on new data, it is important to understand overfitting.  Supervised learning models are designed to minimize error between their predictions of the target value and actuals, in the data they are given.  This last part is key, as frequently in their quest for greater accuracy, machine learning models bias themselves toward picking up on minor idiosyncrasies within the data they are shown.  These idiosyncrasies then don't repeat themselves in subsequent data, meaning those predictions can actually be made less accurate, at the expense of more accurate predictions in the training phase.\n","\n","> The most common way of preventing this is to build models with the concept that a model shouldn't only be judged on its fit to the data it was trained on, but also on \"new\" data.  There are several different ways of operationalizing this, holdout validation, cross-validation, leave-one-out validation, etc.  For our purposes, we'll simply randomly split the data into 3 uneven groups.  The model will be trained on 70% of data, it will then be evaluated on 20% of data to give us an estimate of the accuracy we hope to have on \"new\" data, and 10% will be held back as a final testing dataset which will be used later on."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fdaddc94647214d8a8010196fa8a19e9b1214c80"},"outputs":[],"source":["#model_data = data\n","train_data, validation_data, test_data = np.split(df_train.sample(frac=1, random_state=1729), [int(0.7 * len(df_train)), int(0.9*len(df_train))])  "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7f8e9431bfc4cb46751071672dea48759b3d8675"},"outputs":[],"source":["train_data.shape"]},{"cell_type":"markdown","metadata":{"_uuid":"41d45f009644f45277e1bbae3b7295bc2e6d0d5a"},"source":[">Amazon SageMaker's XGBoost container expects data in the libSVM or CSV data format.  For this example, we'll stick to CSV.  Note that the first column must be the target variable and the CSV should not include headers.  Also, notice that although repetitive it's easiest to do this after the train|validation|test split rather than before.  This avoids any misalignment issues due to random reordering."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b9ae9d642184a0bc13c19b1d32a4ed72c2d74f8c"},"outputs":[],"source":["#pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n","#pd.concat([validation_data['y_yes'], validation_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('validation.csv', index=False, header=False)\n","pd.concat([train_data['SalePrice'], train_data.drop(['SalePrice'], axis=1)], axis=1).to_csv('./data/sm_train.csv', index=False, header=False)\n","pd.concat([validation_data['SalePrice'], validation_data.drop(['SalePrice'], axis=1)], axis=1).to_csv('./data/sm_validation.csv', index=False, header=False)\n","!ls -l ./data"]},{"cell_type":"markdown","metadata":{"_uuid":"0f245d8b920c5b05846afd883ecefd079e799518"},"source":["Now we'll copy the file to S3 for Amazon SageMaker's managed training to pickup."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ce5182b5753983224fdabbbd828e0182244f1490"},"outputs":[],"source":["boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('./data/sm_train.csv')\n","boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('./data/sm_validation.csv')"]},{"cell_type":"markdown","metadata":{"_uuid":"0f82aba28c17baaa339df7f37aecac9e6564910e"},"source":["---\n","## SageMaker\n","### SageMaker Training\n","\n","Yup, that's why we're using XGBoost:\n","\n","> Now we know that most of our features have skewed distributions, some are highly correlated with one another, and some appear to have non-linear relationships with our target variable.  Also, for targeting future prospects, good predictive accuracy is preferred to being able to explain why that prospect was targeted.  Taken together, these aspects make gradient boosted trees a good candidate algorithm.\n","\n","> There are several intricacies to understanding the algorithm, but at a high level, gradient boosted trees works by combining predictions from many simple models, each of which tries to address the weaknesses of the previous models.  By doing this the collection of simple models can actually outperform large, complex models.  Other Amazon SageMaker notebooks elaborate on gradient boosting trees further and how they differ from similar algorithms.\n","\n","> `xgboost` is an extremely popular, open-source package for gradient boosted trees.  It is computationally powerful, fully featured, and has been successfully used in many machine learning competitions.  Let's start with a simple `xgboost` model, trained using Amazon SageMaker's managed, distributed training framework.\n","\n","> First we'll need to specify the ECR container location for Amazon SageMaker's implementation of XGBoost."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"76465e47a370c54d8b8d0510367d6f7bd57411eb"},"outputs":[],"source":["from sagemaker.amazon.amazon_estimator import get_image_uri\n","container = get_image_uri(boto3.Session().region_name, 'xgboost')"]},{"cell_type":"markdown","metadata":{"_uuid":"4adc9dc0d9f92c97f9a658da38e63c80e5753881"},"source":["> Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3, which also specify that the content type is CSV."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1864968074264aa65b384f4f470c8f205bb9da09"},"outputs":[],"source":["s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n","s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"]},{"cell_type":"markdown","metadata":{"_uuid":"05a1a11935223313d5e22e53811101fdf85a2474"},"source":["> First we'll need to specify training parameters to the estimator.  This includes:\n","1. The `xgboost` algorithm container\n","1. The IAM role to use\n","1. Training instance type and count\n","1. S3 location for output data\n","1. Algorithm hyperparameters\n","\n","> And then a `.fit()` function which specifies:\n","1. S3 location for output data.  In this case we have both a training and validation set which are passed in.\n","\n","_Note_: we are about to start a m4.xlarge which cost, as of now, 22.2 cents/hr. It'll run for the duration of our model training."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3907ac643f2eeae424703924c61cd8bf939c7c69"},"outputs":[],"source":["sess = sagemaker.Session()\n","\n","xgb = sagemaker.estimator.Estimator(container,\n","                                    role, \n","                                    train_instance_count=1, \n","                                    train_instance_type='ml.m4.xlarge',\n","                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n","                                    sagemaker_session=sess)\n","\n","# These are the default parameters that came with the Targeting Direct Marketing example\n","xgb.set_hyperparameters(max_depth=5,\n","                        eta=0.2,\n","                        gamma=4,\n","                        min_child_weight=6,\n","                        subsample=0.8,\n","                        silent=0,\n","                        objective='reg:linear',\n","                        num_round=100)\n","\n","xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "]},{"cell_type":"markdown","metadata":{"_uuid":"9f943d056c25acd5e6057eaa5b3a6522aca4a211"},"source":["__Some observations__\n","\n","Launching the instance takes about 2 min to start. That's a long time to be staring at the screen. Once running, training of our algorithm only takes 39 seconds, which is also the amont of time we are billed. That's quite efficient. Think about it. Being able to borrow someone else's computer for 39 seconds.\n","\n","Still, a 39 second process did take nearly 3 min of wall clock time."]},{"cell_type":"markdown","metadata":{"_uuid":"6e23c8e724a56cfc7fac9f829daf69ad4d8ffcee"},"source":["---\n","\n","### Deploying model\n","> Now that we've trained the `xgboost` algorithm on our data, let's deploy a model that's hosted behind a real-time endpoint.\n","\n","This is a 3rd instance we are starting. The first one is used to run this notebook. The second one was used for training our model. And this third one is used for inferences."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"094e4ed084df6d98d8d9d9a7d88969162ac6b901"},"outputs":[],"source":["xgb_predictor = xgb.deploy(initial_instance_count=1,\n","                           instance_type='ml.m4.xlarge')"]},{"cell_type":"markdown","metadata":{"_uuid":"28da14b4148e42c964218917135298f04a45fd7d"},"source":["__Observations__\n","Again, starting a new instance takes several minutes."]},{"cell_type":"markdown","metadata":{"_uuid":"65a5160075e3df26ecde46c270c2c2fef32896b3"},"source":["---\n","\n","### First SM Model Evaluation\n","Let's compare how our SageMaker (SM) model does at predicting SalePrice we already know.\n","\n","> First we'll need to determine how we pass data into and receive data from our endpoint.  Our data is currently stored as NumPy arrays in memory of our notebook instance.  To send it in an HTTP POST request, we'll serialize it as a CSV string \n","then decode the resulting CSV.\n","\n","> *Note: For inference with CSV format, SageMaker XGBoost requires that the data does NOT include the target variable.*"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4de65a21716823b23eed8598cee37432089de987"},"outputs":[],"source":["xgb_predictor.content_type = 'text/csv'\n","xgb_predictor.serializer = csv_serializer"]},{"cell_type":"markdown","metadata":{"_uuid":"40db0ff71c9161aeb5c69c696f13dcee1aa740de"},"source":["Like we did for our training data, we need to convert the categorical columns in the \"test\" data provided by Kaggle to numerical format."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b41ba70648946858090b4886ed7ec5b33486ba17"},"outputs":[],"source":["df_competition = pd.get_dummies(df_competition)\n","df_competition.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"be0eaa2fa3b2b02bcefa169496d6e72a4024faee"},"outputs":[],"source":["df_train.shape"]},{"cell_type":"markdown","metadata":{"_uuid":"1a5f08b1c96be82fb48738ee72e8d9090457a95f"},"source":["__Note__ Our competition test data has 18 fewer columns than our training data. One column is due to the absence of 'SalePrice' from the Kaggle test data, as expected. The rest is due in differences in values present in the various column, and the net impact once apparently categorical data is transformed to numerical data through get_dummies().\n","\n","Since Random Forest, which include XGBoost algorithms, require a fixed number of columns, let's pad our competition with as many columns as required. I will admit that I do not know what impact these useless columns have on the XGBoost algorithm. By not adding a distribution in the data of these columns, I'm hoping it's negligeable.\n","\n","A better way would have been to read and processed all of the data, training + competition, together."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"83266c0aae3f67e1477872e8c714ee7a0fba1eed"},"outputs":[],"source":["df_comp_padded=df_competition\n","for x in range(0, 18):\n","    df_comp_padded[x] = pd.Series(1, index=df_comp_padded.index)\n","df_comp_padded.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e9eff318aa66d35378d28c6b231a70c2aeb077a2"},"outputs":[],"source":["df_comp_padded.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8e794af06396c73d3b17c2f3c1dfcb8e1126ea6d"},"outputs":[],"source":["def predict(data):\n","    ids = data['Id']\n","    saleprice = np.array(xgb_predictor.predict(data.as_matrix()).decode('utf-8').split(',')).astype(np.float)\n","    predictions = list(zip(ids,saleprice))\n","    return predictions\n","\n","#predictions = predict(test_data.drop(['SalePrice'], axis=1).as_matrix())\n","#predictions = predict(kaggle_data.drop(['SalePrice'], axis=1).as_matrix())\n","#predictions = predict(kd.as_matrix())\n","%time predictions = predict(df_comp_padded)"]},{"cell_type":"markdown","metadata":{"_uuid":"61be382701208292b78ebc204437e8d725ff5104"},"source":["__Observations__\n","Asking oru model to predict the saleprice of 1459 houses took about one half second. That feels pretty quick for real-time human interaction.\n","\n","Let's take a quick look at the predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"bea96d97574c0c9ec710a28ab59210c1bd4b1b6f"},"outputs":[],"source":["predictions[0:5]"]},{"cell_type":"markdown","metadata":{"_uuid":"158761eaf7b9fafb6abc2ca3b40f10102a4cef8a"},"source":["They are different than our means-based trivial submission from earlier. Let's submit them and see how the default XGBoost algorithm did.\n","\n","### First SM submission"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8bb392f5accb1f1656ceb0dfc80fd2f74eba4492"},"outputs":[],"source":["np.array(predictions).shape"]},{"cell_type":"markdown","metadata":{"_uuid":"37beeb6e382914af22ef52c80bdbc8bafcbbc04d"},"source":["In terms of shape, it's consistent with the submission requirements, minus the colum headers."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"988c3f4723d13444702aeb85211cd0bc138c0b82"},"outputs":[],"source":["#np.savetxt(\"../data/housing.csv\", predictions, delimiter=\",\", header='Id,SalePrice', fmt='%u')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e979ca2e0e15e2fe6c7907b526108925fcbe06c7"},"outputs":[],"source":["df = pd.DataFrame(predictions, columns=['Id', 'SalePrice'])\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5bb96bb59cf92b08142453cb56b2f9b189262a47"},"outputs":[],"source":["df.to_csv('./data/sub_xgboost_default.csv', header=True, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a1263923b8bf4a108492e97035b4b4cd8d09a773"},"outputs":[],"source":["!kaggle competitions submit -f ./data/sub_xgboost_default.csv -m \"Default XGBoost submission\" house-prices-advanced-regression-techniques\n","#\n","# Damned scroll bar"]},{"cell_type":"markdown","metadata":{"_uuid":"de04a8dcac505a72afab5485c76d9106b29637a8"},"source":["This default XGBoost submittion gives me a public score of 0.17203, which is good for 3640th place as of this writing, a significant improvement on our means-based result! We thus have good confidence we've improved our modeling."]},{"cell_type":"markdown","metadata":{"_uuid":"e6d342486fdc06d65ec2d67ae0227a66de2e8053"},"source":["---\n","\n","## Hyperparameters \n","\n","### Setup\n","Now we'll try to use one of the strength of SageMaker: automated hyperparameter tuning!\n","\n",">*Note, with the default setting below, the hyperparameter tuning job can take about 30 minutes to complete.*\n","\n",">Now that we have prepared the dataset, we are ready to train models. Before we do that, one thing to note is there are algorithm settings which are called \"hyperparameters\" that can dramtically affect the performance of the trained models. For example, XGBoost algorithm has dozens of hyperparameters and we need to pick the right values for those hyperparameters in order to achieve the desired model training results. Since which hyperparameter setting can lead to the best result depends on the dataset as well, it is almost impossible to pick the best hyperparameter setting without searching for it, and a good search algorithm can search for the best hyperparameter setting in an automated and effective way.\n","\n",">We will use SageMaker hyperparameter tuning to automate the searching process effectively. Specifically, we specify a range, or a list of possible values in the case of categorical hyperparameters, for each of the hyperparameter that we plan to tune. SageMaker hyperparameter tuning will automatically launch multiple training jobs with different hyperparameter settings, evaluate results of those training jobs based on a predefined \"objective metric\", and select the hyperparameter settings for future attempts based on previous results. For each hyperparameter tuning job, we will give it a budget (max number of training jobs) and it will complete once that many training jobs have been executed.\n","\n",">Now we configure the hyperparameter tuning job by defining a JSON object that specifies following information:\n","* The ranges of hyperparameters we want to tune\n","* Number of training jobs to run in total and how many training jobs should be run simultaneously. More parallel jobs will finish tuning sooner, but may sacrifice accuracy. We recommend you set the parallel jobs value to less than 10% of the total number of training jobs (we'll set it higher just for this example to keep it short).\n","* The objective metric that will be used to evaluate training results, in this example, we select *validation:auc* to be the objective metric and the goal is to maximize the value throughout the hyperparameter tuning process. One thing to note is the objective metric has to be among the metrics that are emitted by the algorithm during training. In this example, the built-in XGBoost algorithm emits a bunch of metrics and *validation:auc* is one of them. If you bring your own algorithm to SageMaker, then you need to make sure whatever objective metric you select, your algorithm actually emits it.\n","\n",">We will tune four hyperparameters in this examples:\n","* *eta*: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative. \n","* *alpha*: L1 regularization term on weights. Increasing this value makes models more conservative. \n","* *min_child_weight*: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this simply corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is. \n","* *max_depth*: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfitted. \n","\n","Note that I have no idea if these are the correct parameters to tune, nor if their ranges are appropriate. Once again, we don't care so much at the moment as we are just trying to make the end-to-end process work. We have our baseline result above to ensure we don't end up with worse results."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b7c84380bfa46c06fcdbc2369eb43f70a41a8979"},"outputs":[],"source":["from time import gmtime, strftime, sleep\n","tuning_job_name = 'xgboost-tuningjob-' + strftime(\"%d-%H-%M-%S\", gmtime())\n","\n","print (tuning_job_name)\n","\n","tuning_job_config = {\n","    \"ParameterRanges\": {\n","      \"CategoricalParameterRanges\": [],\n","      \"ContinuousParameterRanges\": [\n","        {\n","          \"MaxValue\": \"1\",\n","          \"MinValue\": \"0\",\n","          \"Name\": \"eta\",\n","        },\n","        {\n","          \"MaxValue\": \"10\",\n","          \"MinValue\": \"1\",\n","          \"Name\": \"min_child_weight\",\n","        },\n","        {\n","          \"MaxValue\": \"2\",\n","          \"MinValue\": \"0\",\n","          \"Name\": \"alpha\",            \n","        }\n","      ],\n","      \"IntegerParameterRanges\": [\n","        {\n","          \"MaxValue\": \"10\",\n","          \"MinValue\": \"1\",\n","          \"Name\": \"max_depth\",\n","        }\n","      ]\n","    },\n","    \"ResourceLimits\": {\n","      \"MaxNumberOfTrainingJobs\": 20,\n","      \"MaxParallelTrainingJobs\": 3\n","    },\n","    \"Strategy\": \"Bayesian\",\n","    \"HyperParameterTuningJobObjective\": {\n","      \"MetricName\": \"validation:rmse\",\n","      \"Type\": \"Minimize\"\n","    }\n","  }"]},{"cell_type":"markdown","metadata":{"_uuid":"286646c4172e38af20014c24177729c3716d43e3"},"source":[">Then we configure the training jobs the hyperparameter tuning job will launch by defining a JSON object that specifies following information:\n","* The container image for the algorithm (XGBoost)\n","* The input configuration for the training and validation data\n","* Configuration for the output of the algorithm\n","* The values of any algorithm hyperparameters that are not tuned in the tuning job (StaticHyperparameters)\n","* The type and number of instances to use for the training jobs\n","* The stopping condition for the training jobs\n","\n",">Again, since we are using built-in XGBoost algorithm here, it emits two predefined metrics: *validation:auc* and *train:auc*, and we elected to monitor *validation_auc* as you can see above. One thing to note is if you bring your own algorithm, your algorithm emits metrics by itself. In that case, you'll need to add a MetricDefinition object here to define the format of those metrics through regex, so that SageMaker knows how to extract those metrics.\n","\n","__Note__ I left the default example text above. In our Kaggle competition, we do not want \"validation:auc\", we want \"reg:linear\". Or, acknowledging my undertainty, \"reg:linear\" is closer to what we need."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c1f16bb368960e6989e7b2ec1c9eb6c2540247c6"},"outputs":[],"source":["from sagemaker.amazon.amazon_estimator import get_image_uri\n","training_image = get_image_uri(region, 'xgboost', repo_version='latest')\n","     \n","s3_input_train = 's3://{}/{}/train'.format(bucket, prefix)\n","s3_input_validation ='s3://{}/{}/validation/'.format(bucket, prefix)\n","    \n","training_job_definition = {\n","    \"AlgorithmSpecification\": {\n","      \"TrainingImage\": training_image,\n","      \"TrainingInputMode\": \"File\"\n","    },\n","    \"InputDataConfig\": [\n","      {\n","        \"ChannelName\": \"train\",\n","        \"CompressionType\": \"None\",\n","        \"ContentType\": \"csv\",\n","        \"DataSource\": {\n","          \"S3DataSource\": {\n","            \"S3DataDistributionType\": \"FullyReplicated\",\n","            \"S3DataType\": \"S3Prefix\",\n","            \"S3Uri\": s3_input_train\n","          }\n","        }\n","      },\n","      {\n","        \"ChannelName\": \"validation\",\n","        \"CompressionType\": \"None\",\n","        \"ContentType\": \"csv\",\n","        \"DataSource\": {\n","          \"S3DataSource\": {\n","            \"S3DataDistributionType\": \"FullyReplicated\",\n","            \"S3DataType\": \"S3Prefix\",\n","            \"S3Uri\": s3_input_validation\n","          }\n","        }\n","      }\n","    ],\n","    \"OutputDataConfig\": {\n","      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\n","    },\n","    \"ResourceConfig\": {\n","      \"InstanceCount\": 1,\n","      \"InstanceType\": \"ml.m4.xlarge\",\n","      \"VolumeSizeInGB\": 10\n","    },\n","    \"RoleArn\": role,\n","    \"StaticHyperParameters\": {\n","      \"eval_metric\": \"rmse\",\n","      \"num_round\": \"100\",\n","      \"objective\": \"reg:linear\",\n","      \"rate_drop\": \"0.3\",\n","      \"tweedie_variance_power\": \"1.4\"\n","    },\n","    \"StoppingCondition\": {\n","      \"MaxRuntimeInSeconds\": 43200\n","    }\n","}"]},{"cell_type":"markdown","metadata":{"_uuid":"ce28e0ee50e812c5b9b4c00e3859c8c13fc10cbd"},"source":["__Launch_Hyperparameter_Tuning__\n","\n","Now we can launch a hyperparameter tuning job by calling create_hyper_parameter_tuning_job API. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed.\n","\n","__Costs__ \n","\n","We specified three parallel jobs, so three instances will be commandeered. We'll thus incur three times the cost per hour of our original training."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"af2b326b25c5a86463b9300eefb6f79c3e7a80a9"},"outputs":[],"source":["smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\n","                                            HyperParameterTuningJobConfig = tuning_job_config,\n","                                            TrainingJobDefinition = training_job_definition)"]},{"cell_type":"markdown","metadata":{"_uuid":"fe83e6c35319e14c4d0411218411e9db9e7c1b6f"},"source":["If we go back to the SageMaker dashboard, we can see our three concurrent training jobs!\n","\n",">Let's just run a quick check of the hyperparameter tuning jobs status to make sure it started successfully."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fe0cbf28cef2b5a53ccf4d84de0ad41760f77f1d"},"outputs":[],"source":["smclient.describe_hyper_parameter_tuning_job(\n","    HyperParameterTuningJobName=tuning_job_name)['HyperParameterTuningJobStatus']"]},{"cell_type":"markdown","metadata":{"_uuid":"a25cbba4f1f10e9278fc87287993876a97832f50"},"source":["### Analyze tuning job results\n","\n",">Please refer to \"HPO_Analyze_TuningJob_Results.ipynb\" to see example code to analyze the tuning job results.\n","\n","My best tuning job returned different parameters for XGBoost. But when I tried those, I got substantially the same public leaderboard results. I'll spare you the redundant code to re-train the algorithm and re-submit to the competition.\n","\n","This could be because I picked the wrong parameters to fine tune. But it could also be because the largest possible gains lay elsewhere, perhaps in feature engineering, outlier removal, side effect of bogus columns, etc.\n","\n","At least now, we have a pipeline that enables further experimentation!"]},{"cell_type":"markdown","metadata":{"_uuid":"33aeb760cf7b08218d2827df0863831e45cbb879"},"source":["### Clean-up\n","\n","If you are done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"29299d5b6bf6c02900b3f46a0b3ac21f99c95f44"},"outputs":[],"source":["sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"]},{"cell_type":"markdown","metadata":{"_uuid":"121406904a4e4c48bf35b1f52b3f6ab66af92572"},"source":["## Conclusions\n","\n","My experience with SageMaker has been positive overall. The platform offers a user-friendly interface with a plethora of pre-built examples that can be easily adapted to specific use cases. Despite leveraging automated hyperparameter tuning, I realize that I've only scratched the surface of SageMaker's capabilities. \n","\n","However, one notable drawback I encountered was the time required for instances to boot up, particularly during casual data exploration. The three-minute wait time for instance initialization often led to interruptions in my workflow and hindered real-time interaction. While I acknowledge that improving my proficiency in managing instances could mitigate this issue, it's worth considering alternatives like Crestle or Papermaker for more seamless data exploration and experimentation.\n","\n","In conclusion, while SageMaker excels in \"real\" research and development or production scenarios, where its robust features are invaluable, for casual data exploration and machine learning studies, turn-key solutions might offer a more efficient experience."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":19081,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"notice":"Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},"nbformat":4,"nbformat_minor":4}
